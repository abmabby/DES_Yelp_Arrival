import json
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pytz
from datetime import datetime
from scipy import stats

# å¼•å…¥ statsmodels (å¿…é¡»å®‰è£…: pip install statsmodels)
try:
    from statsmodels.tsa.stattools import adfuller, kpss
    HAS_STATSMODELS = True
except ImportError:
    HAS_STATSMODELS = False
    print("âš ï¸ ä¸¥é‡è­¦å‘Š: æœªå®‰è£… statsmodelsï¼ŒADF/KPSS æ£€éªŒå°†æ— æ³•è¿è¡Œï¼")

# ================= é…ç½®åŒºåŸŸ =================
TARGET_BUSINESS_ID = "FEXhWNCMkv22qG04E83Qjg"
TARGET_YEAR = 2015
TARGET_TIMEZONE = 'America/Chicago' 
DATA_DIR = './data/'
FIGURE_DIR = './figure/'
# ===========================================

def calculate_cohens_d(group1, group2):
    """è®¡ç®—æ•ˆåº”é‡ Cohen's d"""
    n1, n2 = len(group1), len(group2)
    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)
    # åˆå¹¶æ ‡å‡†å·®
    pooled_se = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))
    return (np.mean(group1) - np.mean(group2)) / pooled_se

def step2_ultimate_validation():
    print(f"--- [Module 2] Ultimate Statistical Validation (Academic Rigor) ---")
    os.makedirs(FIGURE_DIR, exist_ok=True)
    
    # 1. æ•°æ®åŠ è½½ä¸æ¸…æ´— (åŒå‰)
    print("1. Loading Data & Timezone Conversion...")
    dates = []
    with open(os.path.join(DATA_DIR, 'checkin.json'), 'r') as f:
        for line in f:
            try:
                data = json.loads(line)
                if data['business_id'] == TARGET_BUSINESS_ID:
                    raw_dates = [datetime.strptime(d.strip(), "%Y-%m-%d %H:%M:%S") for d in data['date'].split(',')]
                    utc = pytz.utc
                    local_tz = pytz.timezone(TARGET_TIMEZONE)
                    for dt in raw_dates:
                        dates.append(utc.localize(dt).astimezone(local_tz))
                    break
            except: continue

    if not dates: return
    df = pd.DataFrame({'dt': dates})
    df = df[df['dt'].dt.year == TARGET_YEAR].copy()
    
    df['date_str'] = df['dt'].dt.date
    df['hour'] = df['dt'].dt.hour
    df['day_of_week'] = df['dt'].dt.dayofweek
    df['is_weekend'] = df['day_of_week'].isin([5, 6]).map({True: 'Weekend', False: 'Weekday'})
    
    print(f"   Sample Size: {len(df)} check-ins")

    # ================= æ£€éªŒ 1: å¹³ç¨³æ€§äº’è¡¥æ£€éªŒ (ADF + KPSS) =================
    print("\nâœ… [Test 1] Stationarity (Complementary Tests)")
    
    # èšåˆæˆæ—¥åº¦åºåˆ— (365å¤©)
    daily_counts = df['date_str'].value_counts().sort_index()
    idx = pd.date_range(start=f'{TARGET_YEAR}-01-01', end=f'{TARGET_YEAR}-12-31')
    daily_counts = daily_counts.reindex(idx, fill_value=0)
    series = daily_counts.values
    
    if HAS_STATSMODELS:
        # 1. ADF Test (åŸå‡è®¾: æœ‰å•ä½æ ¹/éå¹³ç¨³)
        # autolag='AIC': è‡ªåŠ¨æ ¹æ® AIC å‡†åˆ™é€‰æ‹©æœ€ä½³æ»åæœŸï¼Œè§£å†³"æ»åæœŸé€‰æ‹©"è´¨ç–‘
        adf_res = adfuller(series, autolag='AIC')
        adf_stat, adf_p = adf_res[0], adf_res[1]
        used_lag = adf_res[2]
        
        # 2. KPSS Test (åŸå‡è®¾: å¹³ç¨³) -> è¿™æ˜¯ ADF çš„äº’è¡¥æ£€éªŒ
        # 'c': æ£€éªŒå›´ç»•å¸¸æ•°çš„å¹³ç¨³æ€§ (Level Stationarity)
        kpss_res = kpss(series, regression='c', nlags='auto') 
        kpss_stat, kpss_p = kpss_res[0], kpss_res[1]
        
        print(f"   (A) ADF Test (H0: Non-Stationary): p={adf_p:.4e} | Lags Used={used_lag} (Based on AIC)")
        print(f"   (B) KPSS Test (H0: Stationary):    p={kpss_p:.4f}")
        
        # è”åˆåˆ¤å†³é€»è¾‘
        if adf_p < 0.05 and kpss_p > 0.05:
            print("   ğŸ‘‰ ç»“è®º: [Strictly Stationary]. (ADFæ‹’ç»éå¹³ç¨³ + KPSSæ¥å—å¹³ç¨³)")
        elif adf_p < 0.05 and kpss_p < 0.05:
            print("   ğŸ‘‰ ç»“è®º: [Difference Stationary]. å¯èƒ½å­˜åœ¨ç»“æ„çªå˜ï¼Œä½†æ•´ä½“å¯ç”¨ã€‚")
        else:
            print("   ğŸ‘‰ ç»“è®º: [Non-Stationary]. æ•°æ®æœ‰é£é™©ã€‚")

    # ================= æ£€éªŒ 2: æ­£æ€æ€§ä¸ç›¸å…³æ€§ç¨³å¥æ£€éªŒ =================
    print("\nâœ… [Test 2] Normality & Robust Correlation")
    
    # æ„é€  Hourly Profile (24å°æ—¶å‡å€¼)
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç”¨"æ¯å°æ—¶çš„å¹³å‡åˆ°è¾¾æ•°"æ¥ç®—ç›¸å…³æ€§ï¼Œè€Œä¸æ˜¯æ¦‚ç‡å¯†åº¦ï¼Œè¿™æ ·æ›´èƒ½åæ˜ å¼ºåº¦
    weekday_hourly = df[df['is_weekend']=='Weekday'].groupby('hour').count()['dt'] / (365 * 5/7) # ä¼°ç®—
    weekend_hourly = df[df['is_weekend']=='Weekend'].groupby('hour').count()['dt'] / (365 * 2/7)
    
    # é‡æ–°å¯¹å…¶ç´¢å¼• 0-23ï¼Œè¡¥0
    vec_wd = np.array([weekday_hourly.get(h, 0) for h in range(24)])
    vec_we = np.array([weekend_hourly.get(h, 0) for h in range(24)])
    
    # 1. Shapiro-Wilk æ­£æ€æ€§æ£€éªŒ
    # å¦‚æœ p < 0.05ï¼Œè¯´æ˜æ•°æ®éæ­£æ€ -> å¿…é¡»ç”¨ Spearman
    shapiro_wd = stats.shapiro(vec_wd)
    shapiro_we = stats.shapiro(vec_we)
    print(f"   Shapiro-Wilk (Weekday): p={shapiro_wd.pvalue:.4f}")
    print(f"   Shapiro-Wilk (Weekend): p={shapiro_we.pvalue:.4f}")
    is_normal = (shapiro_wd.pvalue > 0.05) and (shapiro_we.pvalue > 0.05)
    
    # 2. ç›¸å…³æ€§
    corr_p, _ = stats.pearsonr(vec_wd, vec_we)
    corr_s, _ = stats.spearmanr(vec_wd, vec_we)
    
    print(f"   Pearson r (Linear):   {corr_p:.4f}")
    print(f"   Spearman Ï (Rank):    {corr_s:.4f} (æ¨èä½¿ç”¨ï¼Œå› æ•°æ®å¯èƒ½éæ­£æ€)")

    # ================= æ£€éªŒ 3: å·®å¼‚æ¥æºå®šä½ä¸æ•ˆåº”é‡ =================
    print("\nâœ… [Test 3] Difference Source & Effect Size")
    
    # æˆ‘ä»¬éœ€è¦æ¯”è¾ƒçš„æ˜¯ï¼šæ¯å°æ—¶åˆ°è¾¾æ•°çš„åˆ†å¸ƒã€‚
    # æ¯”å¦‚ï¼šWeekday çš„ 24 ä¸ªç‚¹ vs Weekend çš„ 24 ä¸ªç‚¹
    # Mann-Whitney U Test: æ£€éªŒä¸¤ä¸ªåˆ†å¸ƒçš„ä¸­ä½æ•°æ˜¯å¦æœ‰æ˜¾è‘—å·®å¼‚ (Non-parametric t-test)
    # H0: Weekday å’Œ Weekend çš„å¼ºåº¦ä¸€æ ·
    # H1: Weekend çš„å¼ºåº¦æ˜¾è‘—é«˜äº Weekday
    u_stat, u_p = stats.mannwhitneyu(vec_wd, vec_we, alternative='two-sided')
    
    # Cohen's d (æ•ˆåº”é‡)
    d_val = calculate_cohens_d(vec_we, vec_wd)
    
    print(f"   Mann-Whitney U Test: p={u_p:.4e}")
    print(f"   Cohen's d: {d_val:.4f}")
    
    if d_val > 0.8:
        effect_desc = "Large Effect (å·¨å¤§å·®å¼‚)"
    elif d_val > 0.5:
        effect_desc = "Medium Effect (ä¸­ç­‰å·®å¼‚)"
    else:
        effect_desc = "Small Effect"
        
    print(f"   ğŸ‘‰ æ•ˆåº”é‡è§£è¯»: {effect_desc}. Weekend æ˜æ˜¾æ¯” Weekday å¿™ã€‚")
    print(f"   ğŸ‘‰ ç»“è®º: K-S æ£€éªŒçš„å·®å¼‚ä¸ä»…æ¥è‡ªå½¢çŠ¶ï¼Œæ›´æ¥è‡ªã€å¼ºåº¦(Intensity)ã€‘çš„æ˜¾è‘—ä¸åŒã€‚")

    # ================= ç»˜å›¾ï¼šå¸¦ç»Ÿè®¡æ ‡æ³¨çš„å¯¹æ¯”å›¾ =================
    plt.figure(figsize=(10, 6))
    plt.plot(range(24), vec_wd, 'b-o', label='Weekday (Avg Rate)', linewidth=2)
    plt.plot(range(24), vec_we, 'r-s', label='Weekend (Avg Rate)', linewidth=2)
    
    plt.title(f"Arrival Intensity Comparison\nSpearman Ï={corr_s:.2f}, Mann-Whitney p={u_p:.2e}, Cohen's d={d_val:.2f}", fontsize=12)
    plt.xlabel("Hour of Day")
    plt.ylabel("Average Arrivals per Hour")
    plt.xticks(range(0, 24))
    plt.grid(alpha=0.3)
    plt.legend()
    plt.savefig(os.path.join(FIGURE_DIR, 'stat_ultimate_comparison.png'), dpi=300)
    plt.show()

if __name__ == "__main__":
    step2_ultimate_validation()