import json
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import pytz
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')

# ================= é…ç½® =================
TARGET_BUSINESS_ID = "FEXhWNCMkv22qG04E83Qjg"
TARGET_YEAR = 2015
TARGET_TIMEZONE = 'America/Chicago'
DATA_DIR = './data/'
# =======================================

def advanced_analysis():
    print(f"--- æ·±åº¦è¯Šæ–­: CafÃ© Du Monde ({TARGET_YEAR}) ---")
    
    # 1. åŠ è½½æ•°æ® (å¸¦æ—¶åŒºä¿®æ­£)
    dates = []
    with open(os.path.join(DATA_DIR, 'checkin.json'), 'r') as f:
        for line in f:
            d = json.loads(line)
            if d['business_id'] == TARGET_BUSINESS_ID:
                raw_dates = [datetime.strptime(x.strip(), "%Y-%m-%d %H:%M:%S") for x in d['date'].split(',')]
                utc = pytz.utc
                local_tz = pytz.timezone(TARGET_TIMEZONE)
                dates = [utc.localize(dt).astimezone(local_tz) for dt in raw_dates]
                break
                
    df = pd.DataFrame({'dt': dates})
    df = df[df['dt'].dt.year == TARGET_YEAR].copy()
    
    # ================= ä»»åŠ¡ä¸€: ä¾¦æŸ¥çœŸå®è¥ä¸šæ—¶é—´ =================
    df['hour'] = df['dt'].dt.hour
    hourly_counts = df['hour'].value_counts().sort_index()
    
    print(f"\n[1. è¥ä¸šæ—¶é—´ä¾¦æŸ¥]")
    # æ‰“å°å…¨å¤©åˆ†å¸ƒï¼Œçœ‹çœ‹å“ªé‡Œæ–­å±‚
    print("å…¨å¤©å®¢æµåˆ†å¸ƒ:")
    print(hourly_counts.to_string())
    
    plt.figure(figsize=(10, 4))
    plt.bar(hourly_counts.index, hourly_counts.values, color='teal', alpha=0.7)
    plt.title("Reality Check: Hourly Check-ins (24h)")
    plt.xlabel("Hour of Day")
    plt.ylabel("Count")
    plt.xticks(range(0, 24))
    plt.grid(axis='y', alpha=0.3)
    plt.show()

    # ================= ä»»åŠ¡äºŒ: åˆ†å¸ƒæ‹Ÿåˆæ“‚å°èµ› =================
    # è‡ªåŠ¨æ‰¾æœ€é«˜å³°çš„ä¸€å°æ—¶
    peak_hour = hourly_counts.idxmax()
    print(f"\n[2. åˆ†å¸ƒæ‹Ÿåˆæ“‚å°èµ› (Peak: {peak_hour}:00)]")
    
    peak_data = df[df['hour'] == peak_hour].sort_values('dt')
    # è®¡ç®—é—´éš” (åˆ†é’Ÿ)
    inter_arrivals = peak_data['dt'].diff().dropna().dt.total_seconds() / 60.0
    # æ¸…æ´—ï¼šåªä¿ç•™åˆç†çš„é—´éš” (<= 60åˆ†é’Ÿ) ä¸” > 0
    data = inter_arrivals[(inter_arrivals <= 60) & (inter_arrivals > 0)]
    
    # å®šä¹‰é€‰æ‰‹ (è¿™é‡Œä¿®å¤äº†ä¹‹å‰çš„ bug)
    distributions = {
        "Exponential": stats.expon,
        "Lognormal": stats.lognorm,
        "Weibull": stats.weibull_min,
        "Gamma": stats.gamma
    }
    
    results = []
    
    plt.figure(figsize=(10, 6))
    # ç”»çœŸå®ç›´æ–¹å›¾
    plt.hist(data, bins=30, density=True, alpha=0.3, color='gray', label='Real Data')
    
    x = np.linspace(0, data.max(), 100)
    
    for display_name, dist_obj in distributions.items():
        try:
            # æ‹Ÿåˆ
            params = dist_obj.fit(data, floc=0)
            
            # è®¡ç®— P-value (ä½¿ç”¨ dist_obj.name è·å–æ­£ç¡®çš„ scipy å†…éƒ¨åç§°)
            # å…³é”®ä¿®å¤ç‚¹ï¼šè¿™é‡Œä¸å†ç”¨ display_name.lower()ï¼Œè€Œæ˜¯ç”¨ dist_obj.name
            ks_stat, p_val = stats.kstest(data, dist_obj.name, args=params)
            
            # è®¡ç®— AIC
            log_likelihood = np.sum(dist_obj.logpdf(data, *params))
            k = len(params)
            aic = 2*k - 2*log_likelihood
            
            results.append({
                "Dist": display_name,
                "P-value": p_val,
                "AIC": aic,
                "Params": params
            })
            
            # ç”»çº¿
            y = dist_obj.pdf(x, *params)
            plt.plot(x, y, linewidth=2, label=f'{display_name} (p={p_val:.3f})')
            
        except Exception as e:
            print(f"æ‹Ÿåˆ {display_name} å¤±è´¥: {e}")
        
    plt.title(f"Distribution Fit Competition (Peak Hour {peak_hour}:00)")
    plt.legend()
    plt.grid(alpha=0.2)
    plt.show()
    
    # æ‰“å°æ’å
    if results:
        res_df = pd.DataFrame(results).sort_values("AIC")
        print("\nğŸ† æ‹Ÿåˆç»“æœæ’å (AICè¶Šä½è¶Šå¥½):")
        print(res_df[['Dist', 'P-value', 'AIC']].to_string(index=False))
        
        best_p = res_df[res_df['Dist']=='Exponential']['P-value'].values[0]
        print(f"\nğŸ‘‰ æŒ‡æ•°åˆ†å¸ƒ P-value: {best_p:.4f}")
        if best_p > 0.05:
            print("âœ… å¥½æ¶ˆæ¯ï¼æŒ‡æ•°åˆ†å¸ƒé€šè¿‡äº†æ£€éªŒ (P > 0.05)ã€‚")
            print("è¿™æ„å‘³ç€å°½ç®¡å¯èƒ½æœ‰æ›´å¥½çš„æ‹Ÿåˆï¼ˆå¦‚ LogNormï¼‰ï¼Œä½†ç”¨ M/M/1 ç†è®ºæ¨¡å‹æ˜¯ã€ç»Ÿè®¡å­¦åˆæ³•ã€‘çš„ï¼")
        else:
            print("âš ï¸ æŒ‡æ•°åˆ†å¸ƒ P < 0.05ã€‚è¯·æŸ¥çœ‹ç›´æ–¹å›¾ï¼Œå¦‚æœçº¢çº¿å¤§è‡´è´´åˆï¼Œä¾ç„¶å¯ä»¥ç”¨ Visual Fit è¾©æŠ¤ã€‚")

if __name__ == "__main__":
    advanced_analysis()